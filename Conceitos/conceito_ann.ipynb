{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40c8f5d4-3c83-4fc7-bfc2-ccf4e038bb19",
   "metadata": {},
   "source": [
    "# Conceitos de Redes Neurais Artificiais (ANN)\n",
    "\n",
    "## ü§ñ O que √© uma Rede Neural Artificial?\n",
    "\n",
    "Uma **Rede Neural Artificial (ANN)** √© um modelo inspirado no funcionamento do c√©rebro humano, composta por neur√¥nios artificiais organizados em camadas.\n",
    "\n",
    "### Camadas de uma ANN:\n",
    "- **Camada de entrada:** recebe os dados (ex: pixels de imagem, atributos num√©ricos)\n",
    "- **Camadas ocultas:** processam os dados internamente com fun√ß√µes de ativa√ß√£o\n",
    "- **Camada de sa√≠da:** gera a predi√ß√£o (ex: classifica√ß√£o, valor num√©rico)\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Perceptron\n",
    "\n",
    "O **perceptron** √© a unidade b√°sica da rede:\n",
    "\n",
    "- Recebe m√∫ltiplas entradas\n",
    "- Aplica pesos e um vi√©s (bias)\n",
    "- Calcula a soma ponderada dos inputs\n",
    "- Aplica uma **fun√ß√£o de ativa√ß√£o** ao resultado\n",
    "\n",
    "√â o bloco fundamental para redes maiores.\n",
    "\n",
    "---\n",
    "\n",
    "## üîå Fun√ß√µes de ativa√ß√£o\n",
    "\n",
    "As fun√ß√µes de ativa√ß√£o tornam o modelo **n√£o linear**, permitindo resolver problemas complexos.\n",
    "\n",
    "Principais fun√ß√µes:\n",
    "\n",
    "- **Sigmoid:** sa√≠da entre 0 e 1. Boa para classifica√ß√£o bin√°ria\n",
    "- **Tanh:** sa√≠da entre -1 e 1. Zero centrada\n",
    "- **ReLU (Rectified Linear Unit):** `f(x) = max(0, x)` ‚Äì padr√£o para camadas ocultas\n",
    "- **Softmax:** transforma vetores em probabilidades. Usada na camada final para classifica√ß√£o multiclasses\n",
    "\n",
    "---\n",
    "\n",
    "## üì§ Forward propagation\n",
    "\n",
    "√â o **processo de propaga√ß√£o dos dados da entrada at√© a sa√≠da**. A cada camada:\n",
    "1. Calcula-se a combina√ß√£o linear: `z = w¬∑x + b`\n",
    "2. Aplica-se uma fun√ß√£o de ativa√ß√£o: `a = f(z)`\n",
    "3. Passa-se o resultado para a pr√≥xima camada\n",
    "\n",
    "---\n",
    "\n",
    "## üîÅ Backpropagation\n",
    "\n",
    "√â o processo de **ajustar os pesos** da rede com base no erro da predi√ß√£o. Envolve:\n",
    "- C√°lculo do erro (fun√ß√£o de perda)\n",
    "- Derivadas parciais (gradientes)\n",
    "- Atualiza√ß√£o dos pesos com base no gradiente (descida do gradiente)\n",
    "\n",
    "Esse processo √© repetido em m√∫ltiplas **√©pocas** durante o treinamento.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Overfitting\n",
    "\n",
    "Quando o modelo **memoriza os dados de treino**, mas **n√£o generaliza** para novos dados.\n",
    "\n",
    "Solu√ß√µes:\n",
    "- **Regulariza√ß√£o:** t√©cnicas como Dropout e L2\n",
    "- **EarlyStopping:** parar o treinamento quando a valida√ß√£o piora\n",
    "- **Mais dados** ou **simplificar a rede**\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Resumo\n",
    "\n",
    "- ANNs s√£o compostas por camadas de neur√¥nios artificiais\n",
    "- Cada camada transforma os dados com pesos, bias e ativa√ß√£o\n",
    "- O treinamento ajusta os pesos para minimizar o erro\n",
    "- Fun√ß√µes de ativa√ß√£o s√£o cruciais para a capacidade da rede\n",
    "- T√©cnicas de regulariza√ß√£o ajudam a evitar overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce76200f-bd34-46e1-bb9e-42eb5e151b15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
